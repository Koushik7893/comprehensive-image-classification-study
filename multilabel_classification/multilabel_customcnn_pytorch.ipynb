{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZMWYFdowkpS"
      },
      "source": [
        "# Multi-label Image Classification with PyTorch\n",
        "\n",
        "* Using a **small real dataset**: Cats vs Dogs\n",
        "* Simulating a **multi-label setup**\n",
        "* Architecture: **Custom CNN**\n",
        "* Loss: `BCEWithLogitsLoss` (which internally applies sigmoid)\n",
        "* Output: 3 labels — `[dog, cat, indoor]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c6fwiuRudHV",
        "outputId": "41c4504d-d109-43ea-a56e-9a8eb0d64863"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision scikit-learn --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DgvIqpTwncv"
      },
      "source": [
        "### Import Required Libraries\n",
        "\n",
        "We import:\n",
        "\n",
        "* PyTorch (core, nn, optim)\n",
        "* Torchvision for image transforms and dataset loading\n",
        "* scikit-learn for evaluation metrics\n",
        "* Pillow for image handling\n",
        "* NumPy for tensor manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dPzL6_bAukgQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkGEdqHRJKbx"
      },
      "source": [
        "### Set Device\n",
        "- Set the computation device to GPU (if available) or CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ_DXImdH2Zb",
        "outputId": "61c782ec-b585-4f01-d0e5-f67d0a8e5757"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLnwJ4rJGhxz"
      },
      "source": [
        "### Define Image Transforms\n",
        "\n",
        "We define standard preprocessing steps:\n",
        "\n",
        "* Resize image to `128x128`\n",
        "* Convert image to PyTorch Tensor (range `[0, 1]`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NA7Ci3eXDXPr"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf2WzARAGgM-"
      },
      "source": [
        "### Download and Load Dataset\n",
        "\n",
        "We use TensorFlow's **\"cats\\_and\\_dogs\\_filtered\"** dataset.\n",
        "\n",
        "* Download ZIP manually and extract it using Python\n",
        "* This gives two classes: `cats/` and `dogs/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oWIkGd6sDX2r"
      },
      "outputs": [],
      "source": [
        "root_dir = \"./cats_vs_dogs\"\n",
        "url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
        "\n",
        "import zipfile, requests, shutil\n",
        "\n",
        "zip_path = \"cats_and_dogs_filtered.zip\"\n",
        "if not os.path.exists(zip_path):\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(zip_path, \"wb\") as f:\n",
        "        shutil.copyfileobj(r.raw, f)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZGkpNM-GeJv"
      },
      "source": [
        "### Simulate Multi-label Targets\n",
        "\n",
        "The original dataset is **single-label**, so we simulate:\n",
        "\n",
        "| Label | \\[dog, cat, indoor]  |\n",
        "| ----- | -------------------- |\n",
        "| dog   | \\[1, 0, random(0/1)] |\n",
        "| cat   | \\[0, 1, random(0/1)] |\n",
        "\n",
        "> ✅ This simulates real-world **multi-label scenarios** like:\n",
        ">\n",
        "> * A dog photo that’s also indoors\n",
        "> * A cat that could be indoors or outdoors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqdO4QzdGZaK"
      },
      "source": [
        "### Custom PyTorch Dataset Class\n",
        "\n",
        "We create a custom Dataset that:\n",
        "\n",
        "* Iterates through `cats/` and `dogs/` folders\n",
        "* Loads images and assigns simulated multi-label targets\n",
        "* Applies transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dgd_-wN7DbBe"
      },
      "outputs": [],
      "source": [
        "class MultiLabelDogCatDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        classes = ['cats', 'dogs']\n",
        "        label_map = {'cats': [0, 1, 0], 'dogs': [1, 0, 0]}  # [dog, cat, indoor]\n",
        "\n",
        "        for class_name in classes:\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            for img_name in os.listdir(class_dir)[:300]:  # use only 300 per class\n",
        "                img_path = os.path.join(class_dir, img_name)\n",
        "                base_label = label_map[class_name].copy()\n",
        "                base_label[2] = random.choice([0, 1])  # simulate indoor\n",
        "                self.images.append(img_path)\n",
        "                self.labels.append(base_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.images[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZoSS8jDGXcn"
      },
      "source": [
        "### Split Dataset and Create DataLoaders\n",
        "\n",
        "We:\n",
        "\n",
        "* Split into `80% train`, `20% val`\n",
        "* Use `DataLoader` for efficient batching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rodisw-rDiVu"
      },
      "outputs": [],
      "source": [
        "data_dir = \"./cats_and_dogs_filtered/train\"\n",
        "dataset = MultiLabelDogCatDataset(data_dir, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wnaC9d0FS_q",
        "outputId": "00d83d0e-45f6-4f2a-eb29-321eea873561"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(480, 120)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_size,val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nuVw9CQ6FVxT"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc0qMd8YGVMc"
      },
      "source": [
        "### Define Custom CNN Model\n",
        "\n",
        "A lightweight CNN:\n",
        "\n",
        "* 2 Convolutional layers with ReLU and MaxPool\n",
        "* Flatten → Dense → ReLU → Dense output with 3 logits\n",
        "* **No `sigmoid` at the end**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ExCIMK3GPj6"
      },
      "source": [
        "### Why No Sigmoid in the Model?\n",
        "\n",
        "> ❗ **Important**: We do **not** apply sigmoid inside the model because `BCEWithLogitsLoss` already does it.\n",
        "\n",
        "If we **manually apply `sigmoid` before passing to `BCEWithLogitsLoss`**, it causes:\n",
        "\n",
        "* **Vanishing gradients**\n",
        "* **Incorrect loss scaling**\n",
        "* **Lower accuracy**\n",
        "\n",
        ">  Instead, use **raw logits**, and apply `sigmoid()` **only at inference time** (for probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JqELMvo1FZpb"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 32 * 32, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x  # no sigmoid here\n",
        "\n",
        "model = SimpleCNN().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFQ00uNAGM50"
      },
      "source": [
        "### Compile and Set Up Training\n",
        "\n",
        "We define:\n",
        "\n",
        "* **Loss**: `BCEWithLogitsLoss()` — used for multi-label tasks\n",
        "* **Optimizer**: Adam with learning rate 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aunVR67XFcY-"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY-FRezjGLKV"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "We:\n",
        "\n",
        "* Loop through each epoch\n",
        "* Zero gradients, forward pass, compute loss\n",
        "* Backprop and optimizer step\n",
        "* Track loss for monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj5C6DRKFedS",
        "outputId": "f98d3acd-7444-4a62-c735-d53a2f66527c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.7998\n",
            "Epoch 2, Loss: 0.6932\n",
            "Epoch 3, Loss: 0.6922\n",
            "Epoch 4, Loss: 0.6929\n",
            "Epoch 5, Loss: 0.6883\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M83ZWhUGJgm"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "After training:\n",
        "\n",
        "* Set model to `eval()` mode\n",
        "* Use `sigmoid()` to convert logits to probabilities\n",
        "* Apply `threshold (0.5)` to get binary predictions\n",
        "* Collect true and predicted labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rWuTapfdFhIn"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.sigmoid(outputs).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "        all_targets.append(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hYD2GpyJFjqt"
      },
      "outputs": [],
      "source": [
        "y_pred = np.vstack(all_preds)\n",
        "y_true = np.vstack(all_targets)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOtcUAIpFlav",
        "outputId": "107108ac-a7c5-408e-8e30-cf6537484416"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0.48333147, 0.5070958 , 0.5119954 ], dtype=float32),\n",
              " array([1., 0., 0.], dtype=float32))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred[0],y_true[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85uwFG-LGHt3"
      },
      "source": [
        "### Performance Metrics\n",
        "\n",
        "We use scikit-learn:\n",
        "\n",
        "* `classification_report` → Precision, Recall, F1\n",
        "* `multilabel_confusion_matrix` → Confusion matrix per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIbEyQ9iFmqn",
        "outputId": "0c90c275-f860-4487-ceb0-279f0d19f038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         dog       0.50      0.38      0.43        55\n",
            "         cat       0.55      0.63      0.59        65\n",
            "      indoor       0.49      0.81      0.61        58\n",
            "\n",
            "   micro avg       0.51      0.61      0.56       178\n",
            "   macro avg       0.51      0.61      0.54       178\n",
            "weighted avg       0.52      0.61      0.55       178\n",
            " samples avg       0.53      0.60      0.54       178\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true, y_pred_binary, target_names=[\"dog\", \"cat\", \"indoor\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26Kpo4-9FsHf",
        "outputId": "b32f2532-a37d-4d1f-a846-df46e146342b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion matrix for class 0:\n",
            "[[44 21]\n",
            " [34 21]]\n",
            "\n",
            "Confusion matrix for class 1:\n",
            "[[22 33]\n",
            " [24 41]]\n",
            "\n",
            "Confusion matrix for class 2:\n",
            "[[13 49]\n",
            " [11 47]]\n"
          ]
        }
      ],
      "source": [
        "conf_matrices = multilabel_confusion_matrix(y_true, y_pred_binary)\n",
        "for i, cm in enumerate(conf_matrices):\n",
        "    print(f\"\\nConfusion matrix for class {i}:\\n{cm}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngx7QLWDGGBd"
      },
      "source": [
        "### If You Have GPU + Large Storage\n",
        "\n",
        "You can try with:\n",
        "\n",
        "* **Open Images Dataset** (via TFDS or direct download)\n",
        "* Contains **real multi-labels** (e.g., person + tree + car)\n",
        "* Requires:\n",
        "\n",
        "  * Label parsing (CSV or JSON)\n",
        "  * Filtering useful categories\n",
        "  * Handling missing/partial annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS7zt_zTGGUS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
